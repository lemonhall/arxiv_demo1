from playwright.sync_api import sync_playwright
import random
import time
from datetime import datetime

def arxiv_standard_crawler():
    with sync_playwright() as p:
        # ===== æµè§ˆå™¨é…ç½® =====
        browser = p.chromium.launch(
            headless=False,
            channel="chrome",
            args=[
                "--start-maximized",
                f"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{random.randint(110, 125)}.0.0.0 Safari/537.36"
            ],
            slow_mo=500
        )

        context = browser.new_context(
            viewport={"width": 1920, "height": 1080},
            locale="en-US"
        )

        # ===== èµ„æºè¿‡æ»¤ =====
        def route_interceptor(route):
            if any(ext in route.request.url for ext in [".jpg", ".png", ".gif"]):
                route.abort()
            else:
                route.continue_()
        context.route("**/*", route_interceptor)

        page = context.new_page()

        try:
            # ===== è®¿é—®é¡µé¢ =====
            print(f"ğŸ•’ {datetime.now().strftime('%H:%M:%S')} è®¿é—®arXiv...")
            page.goto(
                "https://arxiv.org/list/cs.AI/recent?skip=0&show=250",
                timeout=30000,
                wait_until="domcontentloaded"
            )
            
            # ===== ç­‰å¾…åŠ è½½ =====
            title_selector = "dd div.list-title.mathjax"
            for _ in range(3):
                if page.locator(title_selector).count() > 0:
                    break
                time.sleep(2)
                page.mouse.wheel(0, 500)
            else:
                raise Exception("å…ƒç´ åŠ è½½è¶…æ—¶")

            # ===== æ•°æ®æå– =====
            print("ğŸ“Š æå–æ•°æ®ä¸­...")
            titles = page.locator(title_selector).all_inner_texts()
            titles = [t.replace("Title:", "").strip() for t in titles]
            
            # ===== ä¼˜åŒ–ç»“æœæ˜¾ç¤º =====
            print(f"\nâœ… æˆåŠŸè·å– {len(titles)} ç¯‡è®ºæ–‡")
            print("æœ€æ–°å®Œæ•´æ ‡é¢˜ï¼š")
            for i, title in enumerate(titles[:50], 1):
                print(f"{i}. {title}")  # å®Œæ•´æ˜¾ç¤ºæ ‡é¢˜
                
                # å¦‚æœéœ€è¦ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå«å®Œæ•´æ ‡é¢˜ï¼‰
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                with open(f"arxiv_full_titles_{timestamp}.txt", "w", encoding="utf-8") as f:
                    f.write("\n".join(titles))
                    
            return titles

        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
            page.screenshot(path="arxiv_error.png")
            raise
        finally:
            time.sleep(2)
            context.close()
            browser.close()

if __name__ == "__main__":
    print("ğŸš€ arXivçˆ¬è™«å¯åŠ¨ï¼ˆå®Œæ•´æ ‡é¢˜ç‰ˆï¼‰")
    start_time = time.time()
    try:
        results = arxiv_standard_crawler()
        print(f"â±ï¸ æ€»è€—æ—¶: {time.time() - start_time:.2f}ç§’")
    except Exception as e:
        print(f"âš ï¸ æ‰§è¡Œå¤±è´¥: {str(e)}")
