#!/usr/bin/env python
"""
ç‹¬ç«‹çš„arXivçˆ¬è™«è„šæœ¬ï¼Œå¯ä»¥ä½œä¸ºå•ç‹¬è¿›ç¨‹è¿è¡Œ
"""
from playwright.sync_api import sync_playwright
import re
import time
from datetime import datetime
import sys

def arxiv_dynamic_crawler():
    with sync_playwright() as p:
        # ===== æµè§ˆå™¨é…ç½® =====
        browser = p.chromium.launch(
            headless=True,  # æ”¹ä¸ºæ— å¤´æ¨¡å¼ä»¥æé«˜ç¨³å®šæ€§
            channel="chrome",
            args=["--start-maximized"],
            slow_mo=500
        )
        context = browser.new_context(viewport={"width": 1920, "height": 1080})
        page = context.new_page()

        try:
            # ===== è®¿é—®ç›®æ ‡é¡µé¢ =====
            print(f"ğŸ•’ {datetime.now().strftime('%H:%M:%S')} è®¿é—®arXiv...", file=sys.stderr)
            page.goto(
                "https://arxiv.org/list/cs.AI/recent?show=250",
                timeout=30000,
                wait_until="domcontentloaded"
            )

            # ===== æå–H3æ–‡æœ¬ =====
            h3_text = page.locator("dl#articles > h3").first.inner_text()
            print(f"ğŸ” åŸå§‹æ–‡æœ¬: {h3_text}", file=sys.stderr)

            # ===== æå–æ—¥æœŸéƒ¨åˆ† =====
            date_match = re.search(r'^([A-Za-z]{3},\s\d{1,2}\s[A-Za-z]{3}\s\d{4})', h3_text)
            if not date_match:
                raise Exception(f"æ— æ³•ä»æ–‡æœ¬ä¸­æå–æ—¥æœŸ: {h3_text}")
            
            arxiv_date_str = date_match.group(1)
            print(f"ğŸ“… arXivå‘å¸ƒæ—¥æœŸ: {arxiv_date_str}", file=sys.stderr)

            # å°†arXivæ—¥æœŸè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼ˆå¦‚ï¼š2025-04-02ï¼‰
            try:
                arxiv_date = datetime.strptime(arxiv_date_str, "%a, %d %b %Y")
                formatted_date = arxiv_date.strftime("%Y-%m-%d")
            except ValueError as e:
                print(f"âš ï¸ æ—¥æœŸæ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ—¥æœŸå­—ç¬¦ä¸²: {str(e)}", file=sys.stderr)
                formatted_date = arxiv_date_str.replace(",", "").replace(" ", "_")

            # ===== è§£æè®ºæ–‡æ•°é‡ =====
            count_match = re.search(r'showing (?:first )?\d+ of (\d+) entries', h3_text)
            if not count_match:
                raise Exception(f"æ— æ³•è§£æè®ºæ–‡æ•°é‡ä¿¡æ¯")
            
            total_entries = int(count_match.group(1))
            print(f"ğŸ“Š æ£€æµ‹åˆ° {total_entries} ç¯‡å½“æ—¥è®ºæ–‡", file=sys.stderr)

            # ===== æå–æ‰€æœ‰æ ‡é¢˜ =====
            title_elements = page.locator("dd div.list-title.mathjax")
            titles = [title.inner_text().replace("Title:", "").strip() 
                     for title in title_elements.all()]
            
            # ===== ç»“æœéªŒè¯ =====
            if len(titles) != total_entries:
                print(f"âš ï¸ æ³¨æ„: å½“å‰é¡µé¢æ˜¾ç¤º {len(titles)} ç¯‡è®ºæ–‡ï¼ˆæ€»æ•° {total_entries} ç¯‡ï¼‰", file=sys.stderr)
                if len(titles) < total_entries:
                    print("ğŸ’¡ å»ºè®®: ä¿®æ”¹URLä¸­çš„showå‚æ•°ä¸ºæ›´å¤§å€¼ï¼Œå¦‚ ?show=500", file=sys.stderr)

            # ===== ä¿å­˜ç»“æœ =====
            filename = f"arxiv_AI_{formatted_date}_({total_entries}entries).txt"
            with open(filename, "w", encoding="utf-8") as f:
                f.write("\n".join(titles[:total_entries]))
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}", file=sys.stderr)
            
            # è¾“å‡ºæœºå™¨å¯è¯»çš„ç»“æœåˆ°æ ‡å‡†è¾“å‡º
            import json
            result = {
                "date": formatted_date,
                "total_entries": total_entries,
                "titles": titles[:total_entries],
                "filename": filename
            }
            print(json.dumps(result))
            
            return 0

        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}", file=sys.stderr)
            page.screenshot(path="arxiv_error.png")
            # è¾“å‡ºé”™è¯¯ä¿¡æ¯åˆ°æ ‡å‡†è¾“å‡ºä»¥ä¾¿è°ƒç”¨è€…å¤„ç†
            import json
            print(json.dumps({"success": False, "error": str(e)}))
            return 1
        finally:
            time.sleep(2)
            context.close()
            browser.close()

if __name__ == "__main__":
    sys.exit(arxiv_dynamic_crawler()) 